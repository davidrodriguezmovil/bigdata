# ‚ûø Apache Kafka &mdash; üêúÔ∏è Conceptos b√°sicos

![Logo Apache Kafka](images/kafka/Apache_Kafka_logo.svg#derecha "Logo Apache Kafka")

Apacha Kafka √© unha plataforma **distribuida** en **tempo real** para **streaming** de datos. Foi desenvolvida por Linkedin e posteriormente donada √° [Apache Software Foundation](https://apache.org/). Est√° escrito en Java e Scala.

Imaxina un servidor de IRC ou de discord pero para aplicaci√≥ns. Hay temas (ou canles) dos que queres falar e cada aplicaci√≥n pode enviar ou ler mensaxes, sen que se perdan.

Se ves do mundo dos microservicios, sonarache o protocolo **MQTT**: **M**essage **Q**ueue **T**elemetry **T**ransport. Este esquema segue un sistema de publicaci√≥n &harr; suscripci√≥n moi parecido ao de Apache Kafka. **MQTT** √© un protocolo cunha especificaci√≥n para a capa de transporte m√°is non o contido o u como funciona a aplicaci√≥n. Os programas con soporte MQTT deber√≠an ser compatibles entre si, por exemplo:

- <https://www.rabbitmq.com/>
- <https://mosquitto.org/>
- <https://joram.ow2.io/>

Nestes sistemas, a√≠nda que se pode producir/consumir mensaxes a distintas velocidades, poder√≠a chegarse a perder algunha. Est√° pensado m√°is para a inxesta en tempo real.

En Kafka non se perden mensaxes, xa que se persisten (gardan) por eso as veces, algunhas persoas consid√©rano como unha base de datos por algunhas das s√∫as caracter√≠sticas de persistencia, recuperaci√≥n de datos, particionamento, etc.

Por outra banda, Apache Kafka est√° dese√±ado para ser depregado como un cluster de varios nodos, fortalecendo as√≠ a s√∫a estabilidade. Emprega o seu propio protocolo de rede, polo que non ten porqu√© ser compatible con MQTT de xeito directo (a√≠nda que existen conectores e implementaci√≥ns para conseguir esta compatibilidade).

A vantaxe de Apache Kafka radica na s√∫a estabilidade xa que √© un sistema que pode estar distribuido e replicado.

![Esquema Kafka](images/kafka/kafka-modelo.png "Esquema Kafka")

Apache Kafka emprega un **commit log** distribuido

## Broker

Un cluster est√° formado por varios brokers de Kafka que se comunican entre si empregando Zookeeper.

Aos servidores de Kafka dun cluster se lles chama Brokers.

Cada broker ten topics e recibe e garda as mensaxes dos produtores e tam√©n permite aos consumidores recoller as mensaxes.

Para o proceso de descubrimento, o cliente (produtor ou consumidor) debe poder resolver por DNS alomenos un broker de kafka (tam√©n chamado bootstrap server). Unha vez se conecta a un servidor, recibir√° a informaci√≥n de como conectar ao cluster enteiro. Ollo, o resto de hosts dos bootstrap servers deben poder resolverse tam√©n.

## Produtor

Os produtores mandan mensaxes aos topics, estes mensaxes escr√≠bense nunha partici√≥n. As mensaxes poden ser enviadas as√≠ncronamente.

Os productores deben recuperarse autom√°ticamente en caso de fallos no broker e deben decidir a que broker escribir. Sempre hai un l√≠der para un topic/partici√≥n dado e se falla, outro cunha r√©plica toma o control.

## Consumidor

Len as mensaxes dos topics/temas/canles. 

Deben manter un rexistro da partici√≥n e do offset porque os brokers de Kafka non te√±en estado (stateless).

Debido a esto poden rebobinar ou saltar a calquera punto nunha partici√≥n. Deben recuperarse autom√°ticamente no caso de fallos no broker.

**Grupos de consumidores**

- Un conxunto de varios consumidores coordinados para consumir os datos xuntos do mesmo topic.

**Que ocorre cando se presenta un fallo na recuperaci√≥n?**

- Se un consumidor morre, ser√° capaz de ler hacia atr√°s dende onde o deixou, empregando o offset e a partici√≥n que ter√° almacenados.
- O grupo de consumidores debe rebalancearse autom√°ticamente no caso que un consumidor do grupo morra ou se son engadidos novos consumidores.


## Topic/Temas

Un topic √© como unha canle de informaci√≥n √° que nos podemos unir para producir/consumir (enviar/recibir) mensaxes. Algo as√≠ como unha sorte de canle dun IRC ou de discord.

As mensaxes que chegan aos topics forman o "data stream" e g√°rdanse como clave/valor. √Ås mensaxes tam√©n se lles pode chamar rexistros (records).

Datos que hai nunha mensaxe:

- **Key**: Chave (pode estar vac√≠a).
- **Value**: Valor (pode estar vac√≠o).
- Tipo de **compresi√≥n**: Ninguha, GZIP, [snappy &rarr; Google, ideas de LZ77](https://en.wikipedia.org/wiki/Snappy_(compression)).
- **Cabeceira** (opcional).
- **Partici√≥n** e **offset**.
- **Timestamp** (marca de tempo).

Kafka sabe en que estado est√° cada consumidor e lle vai enviando as mensaxes.

As mensaxes son inmutables, unha vez se escriben a unha partici√≥n, non poden cambiar.

Poden conter calquer tipo de datos (almac√©nase en formato binario) polo que deberemos serializalos/deserializalos correctamente (codificalos/descodificalos).

‚ö†Ô∏è Non reinventes a roda! Hai librar√≠as que fan todo o traballo de serializaci√≥n/deserializaci√≥n por nos para os formatos que m√°is se soen empregar con Kafka: JSON e Avro.

Un consumidor pode unirse a un t√≥pico (canle) para recibir o seu "data stream".

Debido a arquitectura de alta dispo√±ibilidade de Kafka, cada topic ten un factor de replicaci√≥n ou Replication Factor (idealmente maior a 1). Cada r√©plica √© id√©ntica byte a byte. Se un broker cae, outro broker que ten a r√©plica dos datos pode pasar a servila.

O c√≥digo empregado nos produtores e consumidores deber√≠a ter en conta a propiedade da idempotencia (se recibes a mesma mensaxe duplicada, detectala ou que non afecte).

## Partici√≥ns

Os topics div√≠dense en diferentes partici√≥ns, cada partici√≥n toma a forma dun commit log estruturado.

Est√° ordeada, √© inmutable e as mensaxes eng√°dense ao final. Unha partici√≥n non se pode dividir entre dous ou m√°is brokers ou discos, crear√≠ase unha nova a continuaci√≥n.

**Offset**

As mensaxes de cada partici√≥n te√±en un n√∫mero secuencial asignado chamado offset que indenficia de forma un√≠voca cada mensaxe dentro dunha partici√≥n (o n√∫mero √© √∫nico **dentro** da partici√≥n).

**L√≠der da partici√≥n**

Para cada partici√≥n so un broker pode actuar como l√≠der nesa partici√≥n, o resto poden replicar os datos e son ISR (in-sync replicas).

Os **produtores** so poden enviar os datos ao broker que sexa o l√≠der desa partici√≥n, mentres que os **consumidores** por defecto ler√°n o dato tam√©n do l√≠der (a√≠nda que dende a versi√≥n 2.4 de Kafka, poden lelo de calquera r√©plica sincronizada).

Se cae un l√≠der, unha das r√©plicas que te√±a unha copia sincronizada dos datos, toma o papel de l√≠der.


## Zookeeper

√â un servidor de c√≥digo fonte aberto que permite a coordinaci√≥n distribuida. Baseado no [algorimo de consenso Paxos](https://en.wikipedia.org/wiki/Paxos_(computer_science)).

Manten datos de configuraci√≥n e segue a relaci√≥n de l√≠der-seguidor (leader/follower) ao longo de t√≥dalas partici√≥ns.

En canto √°s versi√≥n de Kafka e Zookeeper:

- Versi√≥ns inferiores e iguais a 2.x precisan Zookeeper de xeito obrigatorio.
- Versi√≥ns 3.x e maiores poden funcionar sen Zookeeper (empregando Kafka Raft/KRaft).
- A partires da versi√≥n 3.3 KRaft consid√©rase estable e v√°lido para contornos de produci√≥n.
- A partires da versi√≥n 4.0 est√° planeado eliminar ZooKeeper.

Mant√©n a lista de brokers no cluster, axuda a elixir o l√≠der de cada partici√≥n e env√≠a as notificaci√≥ns a Kafka no caso de cambios (un broker morre, b√≥rrase un topic, cr√©ase un topic, lev√°ntase un broker...)

Os offsets non se gardan en Zookeper dende a versi√≥n 0.10 de Kafka, agora son os consumidores os que gardan estes offsets en Kafka, nun topic chamado **__consumer__offsets**.

Polo tanto, cando un consumidor morre, poder√° ler este topic e recuperarse xusto dende onde deixou a lectura.

## Cousas da entrega e outras caracter√≠sticas

Acuses de recibo / Confirmaci√≥ns (ACK &mdash; Acknowledgement)

Os produtores poden pedir recibir confirmaci√≥ns das escrituras.

- **acks=0**. O produtor non espera e poder√≠an perderse datos
- **acks=1**. O produtor espera pola confirmaci√≥n do l√≠der (p√©rdida espor√°dica de datos cando cae o l√≠der e non hai copias confirmadas).
- **acks=todas**. O produtor espera pola confirmaci√≥n do l√≠der e das r√©plicas co que idealmente non haber√≠a posbilidade de perda de datos.

Un produtor pode mandar unha "key" coa mensaxe de xeito que mensaxes coa misma "key" vaia √° mesma partici√≥n. Se esta "key" √© null, ent√≥n os datos mandaranse cun algoritmo de Round Robin entre as partici√≥ns.

As mensaxes da mesma partici√≥n mant√©√±ense en orde porque se le en orde de menor a maior offset.

Esta orde non se mant√©n entre partici√≥ns (offsets repetidos en diferentes partici√≥ns, non na mesma) polo que se queremos **todas** as mensaxes ordenadas, deberemos empregar un topic cunha soa partici√≥n.


## M√°is informaci√≥n

- <https://www.confluent.io/resources/kafka-the-definitive-guide/>
- <https://github.com/javicacheiro/pyspark_course/blob/master/supplementary/kafka/>

